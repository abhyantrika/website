<!DOCTYPE html>
<html>
<style>

p {
  font-size: 15px;
}
.bar {
  opacity: 1;
}
.highlight {
  opacity: 0.5;
}

</style>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>NIRVANA</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1.">
    <!-- <base href="/">  -->


<!--     <link rel="apple-touch-icon" href="apple-touch-icon.png"> -->
  <link rel="icon" type="image/png" href="img/seal_icon.png">
    <!-- Place favicon.ico in the root directory -->

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <!--<link rel="stylesheet" href="css/app.css">
    <link rel="stylesheet" href="css/bootstrap.min.css">-->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-110862391-1"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-110862391-1');
    </script>

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.1/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>
    <script src="https://d3js.org/d3.v4.min.js"></script>
    
    <!--<script src="js/app.js"></script>-->
</head>

<body>
    <div class="container" id="main" >
        <div class="row">
            <h2 class="col-md-12 text-center">
              Latent-INR: A Flexible Framework for Implicit Representations of Videos with Discriminative Semantics</br> 
            </h2>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        <a href="http://cs.umd.edu/~shishira/">
                          Shishira R Maiya<sup>*</sup>
                        </a>
                    </li>
                    <li>
                      <a href="https://learn2phoenix.github.io/">
                          Anubhav Gupta <sup>*</sup>
                        </a>
                    </li>
                    <li>
                      <a href="https://mgwillia.github.io/">
                        Matt Gwilliam 
                      </a>
                  </li><br>
                    <li>
                        <a href="https://maxehr.umiacs.io/">
                          Max Ehrlich
                        </a>
                    </li>
                    <li>
                        <a href="https://www.cs.umd.edu/~abhinav/">
                          Abhinav Shrivastava
                        </a>
                    </li>
                </ul>
                University of Maryland, College Park &nbsp;&nbsp;&nbsp;
                
            </div>
        </div>

        <div style="text-align: center" class="row">
          <!-- Move it to center -->
          <br>
            <a href="../data/latent_inr.pdf" >
              <strong>Paper</strong> 
            </a>
        </div>


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <p class="text-justify">
                  Implicit Neural Networks (INRs) have emerged as powerful representations to encode all forms of data, including images, videos, audios, and scenes. With video, many INRs for video have been proposed for the compression task, and recent methods feature significant improvements with respect to encoding time, storage, and reconstruction quality. However, these encoded representations lack semantic meaning, so they cannot be used for any downstream tasks that require such properties, such as retrieval. This can act as a barrier for adoption of video INRs over traditional codecs as they do not offer any significant edge apart from compression. To alleviate this, we propose a flexible framework that decouples the spatial and temporal aspects of the video INR. We accomplish this with a dictionary of per-frame latents that are learned jointly with a set of video specific hypernetworks, such that given a latent, these hypernetworks can predict the INR weights to reconstruct the given frame. This framework not only retains the compression efficiency, but the learned latents can be aligned with features from large vision models, which grants them discriminative properties. We align these latents with CLIP and show good performance for both compression and video retrieval tasks. By aligning with VideoLlama, we are able to perform open-ended chat with our learned latents as the visual inputs. Additionally, the learned latents serve as a proxy for the underlying weights, allowing us perform tasks like video interpolation. These semantic properties and applications, existing simultaneously with ability to perform compression, interpolation, and superresolution properties, are a first in this field of work.                  
                  </p>
            </div>
        </div>



        <div class="row">
            <div class="col-md-8 col-md-offset-2">  

                <h3>
                    1) Overview
                </h3><br>
                <div class="paper" style="float:none; display:inline-block; margin-bottom: 25px;"> 
                    <span style="position: relative; width: 69%; top: 60%; left: 25%; right: 25%; margin-top: -100px; margin-left: -100px;">
                        <img src="latent_inr_teaser.png" alt="Overview" width="75%" ><br><br>
                    </span>
                        
                    <!--<span style="float:left;width: 50%;">
                        <img src="img/hnerv_epoch.jpg" alt="" width="98%" >
                    </span>       -->                         
                </div>
                <p class="text-justify">
                  Prior video INR works perform either pixel-wise or frame-wise prediction. We instead perform spatio-temporal patch-wise prediction and fit individual neural networks to groups of frames (clips) which are initialized using
                  networks trained on the previous group. Such an autoregressive
                  patch-wise approach exploits both spatial and temporal redundancies present in videos while promoting scalability and adaptability
                  to varying video content, resolution or duration.
              </p>


                <h3>
                    2) Model architecture
                </h3><br>
                <div style="margin-bottom: 25px">
                <img src="images/arch_v4_page-0001.jpg" width="100%" alt="Model Architecture">
                </div>

<!-- 
                <h3>
                   7) Citation
                </h3>
       <div class="form-group col-md-10 col-md-offset-1">
    <textarea id="bibtex" class="form-control" rows="10" readonly>
      @InProceedings{Maiya_2023_CVPR,
        author    = {Maiya, Shishira R. and Girish, Sharath and Ehrlich, Max and Wang, Hanyu and Lee, Kwot Sin and Poirson, Patrick and Wu, Pengxiang and Wang, Chen and Shrivastava, Abhinav},
        title     = {NIRVANA: Neural Implicit Representations of Videos With Adaptive Networks and Autoregressive Patch-Wise Modeling},
        booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
        month     = {June},
        year      = {2023},
        pages     = {14378-14387}
        }
    </textarea>
                 </div> 
            </div>
        </div> -->

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <br> The website template was borrowed from <a href="https://bmild.github.io">Ben Mildenhall</a>.
                </p>
            </div>
        </div>
    </div>
</body>
</html>
