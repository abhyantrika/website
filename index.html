<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Shishira R Maiya</title>
  
  <meta name="author" content="Shishira R Maiya">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Shishira R Maiya</name>
              </p>
              <p>I am a PhD Student at <a href="https://www.cs.umd.edu">University of Maryland</a>, under <a href="https://www.cs.umd.edu/~abhinav/">Prof Abhinav Shrivastava </a>
                where I work on computer vision and machine learning. Prior to this I earned my Masters in Computer Science from University of Maryland as well. 
              </p>
                Previously, I finished my undergrad from <a href="http://msrit.edu"> MSRIT </a> Bangalore. My first brush with machine learning 
                was as an intern at <a href="https://stride.ai"> Stride </a> where I worked on text classification and other NLP tasks.
                I later went on to work under <a href="http://mile.ee.iisc.ac.in/AGR/index.htm"> Prof AG Ramakrishnan </a> 
                on super resolution of document images at <a href="http://mile.ee.iisc.ac.in"> MILE </a> lab at <a href ="https://iisc.ac.in" >IISc. </a>
                I continued working in related domains with an internship at <a href=""> Hyperverge </a> under 
                <a href="https://www.linkedin.com/in/adarsh-tadimari-60b00294/?originalSubdomain=in"> Adarsh Tadimari</a>,
                where I worked on scene text recognition and OCR. 
              <p>
                After my undergrad, I worked as a research assistant at <a href="https://cps.iisc.ac.in"> RBCCPS </a> at IISc, under
                <a href="https://scholar.google.co.in/citations?hl=en&user=OftxRCEAAAAJ&view_op=list_works&sortby=pubdate">
                   Prof Raghu Krishnapuram. </a> Here, I worked on a wide variety of problems ranging from multi-camera multi-object tracking, segmentation and 
                   vision guidance for drones. During my Masters, I had the opportunity of working as a research intern for SIML team at <a href="http://apple.com/"> Apple, </a>
                   under <a href="https://www.linkedin.com/in/rui-shen/"> Rui Shen.</a>
              </p>
              <p>
                  I recently worked as a research intern at <a href="https://snap.com"> Snap Inc</a>, where I worked on developing an efficient and scalable 
                  implicit neural representation for videos.
              </p>
              <p>
                Currently my research spans model, data compression techniques and understanding adversarial examples for vision tasks.
              </p>

              <p style="text-align:center">
                <a href="mailto:shishira@umd.edu">Email</a> &nbsp/&nbsp
                <a href="data/shishira_cv.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.co.in/citations?user=43zd4zIAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="http://github.com/abhyantrika/">Github</a> &nbsp/&nbsp
                <a href="https://mathikere.substack.com/">Substack</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/shishira.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/shishira_circle.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <!-- <p>
                I'm interested in computer vision, machine learning, optimization, and image processing. Much of my research is about inferring the physical world (shape, motion, color, light, etc) from images. Representative papers are <span class="highlight">highlighted</span>.
              </p> -->
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/nirvana.png' width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">

              <papertitle>NIRVANA: Neural Implicit Representations of Videos with Adaptive Networks and Autoregressive Patch-wise Modeling</papertitle>
              <br>
              <strong>Shishira R Maiya*</strong>,
              <a href="https://sharath-girish.github.io"> Sharath Girish* </a>,
              <a href="https://maxehr.umiacs.io">Max Ehrlich </a>,
              <a href="https://hywang66.github.io/"> Hanyu Wang</a>,
              <a href="https://www.linkedin.com/in/kwotsin/"> Kwot Sin Lee</a>,
              <a href="https://www.linkedin.com/in/patrick-poirson-62b53248">Patrick Poirson</a>
              <a href="https://pxiangwu.github.io/"> Pengxiang Wu </a>
              <a href="https://www.linkedin.com/in/chen-wang-16251631">Chen Wang</a>,
              <a href="https://www.cs.umd.edu/~abhinav/">Abhinav Shrivastava</a>
              <br>
              <em> IEEE Conference on Computer Vision and Pattern Recognition (CVPR)
              </em>, 2023
              <br>
              <p> An efficient and scalable INR for Videos! </p>
              <a href="Nirvana/index.html">Project Page</a> | 
              <a href="https://arxiv.org/abs/2212.14593">Paper</a>
              
            </td>
          </tr> 

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/freq_perspective.png' width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">

              <papertitle>A Frequency Perspective of Adversarial Robustness</papertitle>
              <br>
               
              <strong>Shishira R Maiya,</strong>
              <a href="https://maxehr.umiacs.io">Max Ehrlich </a>,
              <a href="">Vatsal Agarwal</a>,
              <a href="https://sites.google.com/site/sernam">Ser-Nam Lim</a>,
              <a href="https://www.cs.umd.edu/~tomg/">Tom Goldstein</a>,
              <a href="https://www.cs.umd.edu/~abhinav/">Abhinav Shrivastava</a>
              <br>
              <em> Under Review </em>, 2021
              <br>
              <p> A study of adversarial robustness from the perspective of frequency analysis. </p>
              <a href="https://arxiv.org/abs/2111.00861">Paper</a>
            </td>
          </tr> 


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/lottery.png' width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">

              <papertitle>The Lottery Ticket Hypothesis for Object Recognition</papertitle>
              <br>
               <a href="https://sharath-girish.github.io"> Sharath Girish* </a> , 
              <strong>Shishira R Maiya*,</strong>
              <a href="https://kampta.github.io/">Kamal Gupta </a>,
              <a href="https://haochen-rye.github.io/">Hao Chen</a>,
              <a href="http://users.umiacs.umd.edu/~lsd/">Larry Davis</a>,
              <a href="https://www.cs.umd.edu/~abhinav/">Abhinav Shrivastava</a>
              <br>
              <em> IEEE Conference on Computer Vision and Pattern Recognition (CVPR) </em>, 2021
              <br>
              <p> Explored the nuances of applying the Lottery ticket Hypothesis for Object recognition models.</p>
              <a href="https://lth-recognition.github.io/">Project Page</a> | <a href="https://openaccess.thecvf.com/content/CVPR2021/html/Girish_The_Lottery_Ticket_Hypothesis_for_Object_Recognition_CVPR_2021_paper.html">Paper</a> | <a href="https://github.com/Sharath-girish/LTH-ObjectRecognition">Code</a>              
            </td>
          </tr> 

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/membership_inf.png' width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">

              <papertitle>Membership Inference Attacks on Lottery Ticket Networks</papertitle>
              <br>
               <a href="https://cardwizard.github.io/"> Aadesh Bagmar* </a> , 
              <strong>Shishira R Maiya*,</strong>
              <a href="">Shruti Bidwalkar  </a>,
              <a href="http://www.cs.umd.edu/~amol/">Amol Deshpande</a>
              <br>
              <em> International Conference on Machine Learning (ICML) workshop: A Blessing in Disguise:
                The Prospects and Perils of Adversarial Machine Learning  </em>, 2021
              <br>
              <p> Are lottery ticket networks vulnerable to Membership inference attacks due to their sparse nature?</p>
               <a href="https://arxiv.org/pdf/2108.03506.pdf">Paper</a> | <a href="https://github.com/cardwizard/membershipInferenceLottery">Code</a>
              
            </td>
          </tr> 

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/retina_icassp.png' width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">

              <papertitle>Rethinking Retinal Landmark Localization As Pose Estimation: Naive Single Stacked Network For Optic Disk And Fovea Detection</papertitle>
              <br>
              <strong>Shishira R Maiya*,</strong>
              <a href="https://themadaiguy.github.io/">Puneet Mathur* </a>
              <br>
              <em> IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) </em>, 2020
              <br>
              <p> Can we use pose models for medical imaging problems ? </p>
               <a href="https://ieeexplore.ieee.org/document/9053177">Paper</a> 
            </td>
          </tr> 

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/slum_seg.png' width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Slum Segmentation and Change Detection: A Deep Learning Approach</papertitle>
              <br>
              <strong>Shishira R Maiya*,</strong>
              <a href="https://in.linkedin.com/in/cbsudux">Sudharshan Chandra Babu* </a>
              <br>
              <em> Neural Information Processing Systems (NeurIPS): ML4D workshop </em>, 2018
              <br>
              <p> Detecting and tracking growth of slums in the city of Mumbai using deep learning. </p>
               <a href="https://cbsudux.github.io/Mumbai-slum-segmentation/"> Project Page </a> | <a href="https://arxiv.org/pdf/1811.07896.pdf">Paper</a> | <a href="https://github.com/cbsudux/Mumbai-slum-segmentation">Code</a> 
            </td>
          </tr> 

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/relation_net.png' width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Relation Networks for Optic Disc and Fovea Localization in Retinal Images</papertitle>
              <br>
              <a href="https://in.linkedin.com/in/cbsudux">Sudharshan Chandra Babu* </a>,
              <strong>Shishira R Maiya*</strong>
              <br>
              <em> Neural Information Processing Systems (NeurIPS): ML4Health workshop </em>, 2018
              <br>
              <p> Utilizing context for detection in medical imaging. </p>
               <a href="https://arxiv.org/pdf/1812.00883.pdf">Paper</a>
            </td>
          </tr> 

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <img src='images/doc_images.png' width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>A new approach for upscaling document images for improving their quality</papertitle>
              <br>
              <a href="https://sites.google.com/site/iiscrkpandey/">Rama Krishna Pandey</a>,
              <strong>Shishira R Maiya,</strong>
              <a href="http://mile.ee.iisc.ac.in/AGR/index.htm"> A G Ramakrishnan </a>
              <br>
              <em>  IEEE India Conference (INDICON)  </em>, 2017
              <br>
              <p> Method to upsample Document Images.  </p>
               <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8487796">Paper</a>
            </td>
          </tr> 


      </td>
    </tr>
  </table>
  <tr>
    <td style="padding:0px">
      <br>
      <p style="text-align:right;font-size:small;">
       <a href="https://jonbarron.info/">Template credits</a>
      </p>
    </td>
  </tr>
</body>

</html>
